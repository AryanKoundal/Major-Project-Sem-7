{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries and pulling dataset"
      ],
      "metadata": {
        "id": "taQo15fMe7mj"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-qiINBQSK2g"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.manifold import TSNE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RopL7tUZSQkT"
      },
      "source": [
        "# Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwEPNDWySTKm"
      },
      "source": [
        "# loading the data into a pandas dataFrame\n",
        "dataset = pd.read_csv('clustering.csv')\n",
        "x = dataset.iloc[:, 6:7].values # making the maritx of the job titles\n",
        "y = dataset.iloc[:, -1].values # making matrix of skillsets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert numpyarray to string data type\n",
        "x = np.array(x, dtype=str)\n",
        "x = np.vectorize(lambda p: p.lower())(x)\n",
        "list_of_x = x.tolist()\n",
        "\n",
        "flattened_x = [item for sublist in x for item in sublist]\n",
        "print(flattened_x)\n",
        "# print(list_of_x)"
      ],
      "metadata": {
        "id": "MKJqVV_1twX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data cleaning, Remove single quotes from each element in 'y' and split the strings by commas, creating a list of skills for each job title\n",
        "y = np.array(y, dtype=str)\n",
        "y = np.vectorize(lambda x: x.lower())(y)\n",
        "y = np.core.defchararray.replace(y, \"'\", \"\")\n",
        "# Custom function to remove leading spaces from each word in a string\n",
        "remove_leading_spaces = np.vectorize(lambda x: x.lstrip())\n",
        "# Apply the custom function to the entire array\n",
        "y = remove_leading_spaces(y)\n",
        "y = np.core.defchararray.split(y, ', ')\n",
        "list_of_y = y.tolist()\n",
        "print(list_of_y)"
      ],
      "metadata": {
        "id": "mspU8xD5tyjw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_dict = {}\n",
        "\n",
        "for i in range(len(flattened_x)):\n",
        "    my_dict[flattened_x[i]] = list_of_y[i]\n",
        "\n",
        "print(my_dict)"
      ],
      "metadata": {
        "id": "km0mHJUoNXRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = my_dict.items()\n",
        "# Convert object to a list\n",
        "data = list(result)\n",
        "# Convert list to an array\n",
        "numpyArray = np.array(data)\n",
        "# print the numpy array\n",
        "print(numpyArray)"
      ],
      "metadata": {
        "id": "Bz7mDVulTGQy",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# training model 1"
      ],
      "metadata": {
        "id": "EYbIqI8AGBUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a Word2Vec model on the 'y' data to create word embeddings\n",
        "model = Word2Vec(sentences=y, vector_size=2, window=5, min_count=1, workers=4)\n",
        "print(model.wv)\n",
        "# Print all word vectors\n",
        "for word in model.wv.index_to_key:\n",
        "    print(f\"{word}: {model.wv[word]}\")"
      ],
      "metadata": {
        "id": "spFBj61kTiTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in model.wv.index_to_key:\n",
        "    for key, values in my_dict.items():\n",
        "        for i, value in enumerate(values):\n",
        "            if word == value:\n",
        "                my_dict[key][i] = model.wv[word]\n",
        "\n",
        "# for key, values in my_dict.items():\n",
        "#     print(f\"{key} : {values}\")\n",
        "\n",
        "print(my_dict)"
      ],
      "metadata": {
        "id": "M6FWWXKSXJKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_dict = my_dict\n",
        "for key, values in new_dict.items():\n",
        "    # print(f\"{key} : {values}\")\n",
        "    x_coor = 0\n",
        "    y_coor = 0\n",
        "    for i, value in enumerate(values):\n",
        "        x_coor += value[0]\n",
        "        y_coor += value[1]\n",
        "    new_dict[key] = [x_coor, y_coor]\n",
        "\n",
        "for key, values in new_dict.items():\n",
        "    print(f\"{key} : {values}\")"
      ],
      "metadata": {
        "id": "P1XP5lpXXr7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the 2D word vectors\n",
        "# plt.figure(figsize=(40, 32))\n",
        "plt.figure(figsize=(20, 16))\n",
        "for key, values in new_dict.items():\n",
        "    plt.scatter(values[0], values[1], label=key)\n",
        "\n",
        "# Annotate each point with the word\n",
        "for key, values in new_dict.items():\n",
        "    plt.annotate(key, (values[0], values[1]))\n",
        "\n",
        "plt.title('Job Title Word Vectors')\n",
        "plt.xlabel('Dimension 1')\n",
        "plt.ylabel('Dimension 2')\n",
        "# plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rK1WRUSXZlbu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the 2D word vectors\n",
        "# plt.figure(figsize=(40, 32))\n",
        "plt.figure(figsize=(25, 20))\n",
        "for word in model.wv.index_to_key:\n",
        "    plt.scatter(model.wv[word][0], model.wv[word][1], label=word)\n",
        "\n",
        "# Annotate each point with the word\n",
        "for word in model.wv.index_to_key:\n",
        "    plt.annotate(word, (model.wv[word][0], model.wv[word][1]))\n",
        "\n",
        "plt.title('Skills Word Vectors')\n",
        "plt.xlabel('Dimension 1')\n",
        "plt.ylabel('Dimension 2')\n",
        "# plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DyLqyXC6Yjwc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# job titles"
      ],
      "metadata": {
        "id": "tCr_z9-PLGG6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for skills in y:\n",
        "  for skill in skills:\n",
        "    print(skill)"
      ],
      "metadata": {
        "id": "1uTpN5WPMQ9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create vectors for job titles by aggregating vectors of individual skills for each job title.\n",
        "# job_title_vectors = [values for skills in y for skill in skills]\n",
        "# for i, vector in enumerate(job_title_vectors):\n",
        "#     print(f\"Job Title {i + 1} Vector: {vector}\")\n",
        "\n",
        "job_title_vectors = [values for key, values in new_dict.items()]\n",
        "print(job_title_vectors)"
      ],
      "metadata": {
        "id": "EO_ug9HLTmUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize the job title vectors to have zero mean and unit variance.\n",
        "scaler = StandardScaler()\n",
        "job_title_vectors_scaled = scaler.fit_transform(job_title_vectors)\n",
        "# for i, vector in enumerate(job_title_vectors):\n",
        "#     print(f\"Job Title {i + 1} Vector: {vector}\")\n",
        "\n",
        "print(job_title_vectors)"
      ],
      "metadata": {
        "id": "xh_zHp5FTptX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply t-distributed Stochastic Neighbor Embedding (t-SNE) to reduce the dimensionality of the job title vectors to 2 dimensions\n",
        "tsne = TSNE(n_components=2, random_state=42)\n",
        "job_title_tsne = tsne.fit_transform(job_title_vectors_scaled)"
      ],
      "metadata": {
        "id": "B2QprSEmTtsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using the elbow method to find the optimal number of clusters"
      ],
      "metadata": {
        "id": "aqHPNesSiY_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "wcss = []\n",
        "for i in range(1, 11):\n",
        "    kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42)\n",
        "    kmeans.fit(job_title_vectors_scaled)\n",
        "    wcss.append(kmeans.inertia_)\n",
        "plt.plot(range(1, 11), wcss)\n",
        "plt.title('The Elbow Method')\n",
        "plt.xlabel('Number of clusters')\n",
        "plt.ylabel('WCSS')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XhJGyXXQicwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply K-Means clustering with 8 clusters to the standardized job title vectors\n",
        "kmeans = KMeans(n_clusters=4, random_state=42)\n",
        "clusters = kmeans.fit_predict(job_title_vectors_scaled)"
      ],
      "metadata": {
        "id": "SXBOHWtqTvfp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "# Assuming 'true_labels' are the true labels for your data\n",
        "# 'clusters' are the cluster assignments obtained from clustering algorithm\n",
        "\n",
        "# Evaluate clustering using silhouette score\n",
        "silhouette_avg = silhouette_score(job_title_vectors_scaled, clusters)\n",
        "print(f\"Silhouette Score: {silhouette_avg}\")"
      ],
      "metadata": {
        "id": "e6dvGH6EY82h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the t-SNE transformed job title vectors\n",
        "plt.figure(figsize=(10, 8))\n",
        "scatter = plt.scatter(job_title_tsne[:, 0], job_title_tsne[:, 1], c=clusters, cmap='viridis')\n",
        "plt.title('KMeans Clusters of Job Titles')\n",
        "plt.xlabel('t-SNE Dimension 1')\n",
        "plt.ylabel('t-SNE Dimension 2')\n",
        "plt.legend(*scatter.legend_elements(), title='Clusters')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ixmVIX5vQYPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clusters"
      ],
      "metadata": {
        "id": "vYiTvFbDTnb0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}